model:
  target_model: "Qwen/Qwen2.5-7B"
  target_dtype: "bfloat16"
  draft_model: "Qwen/Qwen2.5-0.5B"
  draft_dtype: "bfloat16"
  device: "auto"
  backend: "huggingface"

decoding:
  speculation_length: 5
  temperature: 1.0
  max_new_tokens: 64

eval:
  datasets:
    - "humaneval"
    - "gsm8k"
    - "mt_bench"
    - "truthfulqa"
  num_samples: 100
  output_dir: "results/router"
  seed: 42

router:
  enabled: true
  embedding_model: "sentence-transformers/all-mpnet-base-v2"
  embedding_dim: 768
  draft_models:
    code: "Qwen/Qwen2.5-0.5B"
    chat: "Qwen/Qwen2.5-0.5B"
    reasoning: "Qwen/Qwen2.5-0.5B"
  training_data_path: "data/router_training.json"
  collection_datasets:
    - "humaneval"
    - "gsm8k"
    - "mt_bench"
    - "truthfulqa"
  collection_num_samples: 100
  collection_max_new_tokens: 64

logging:
  level: "INFO"
  use_wandb: false
